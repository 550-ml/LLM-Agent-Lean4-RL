from src.agent.base import AgentState
from src.llm import LLMConfig
import os
from src.llm.factory import LLMFactory
from .planning_agent import PlanningAgent
from .generation_agent import GenerationAgent
from .verification_agent import VerificationAgent
from ..llm.base import BaseLLM
from typing import Any, Dict, Optional, Union
from ..verifier.lean4_runner import Lean4Runner
from ..llm.config_loader import ConfigLoader
from ..utils.config_manager import ConfigManager
from src.logger import setup_logging
import logging

logger = logging.getLogger(__name__)


class AgentCoordinator:
    """å¤šæ™ºèƒ½ä½“çš„åè°ƒå™¨

    è´Ÿè´£åè°ƒè§„åˆ’ã€ç”Ÿæˆã€éªŒè¯ä¸‰ä¸ªæ™ºèƒ½ä½“çš„å·¥ä½œæµ
    """

    def __init__(
        self,
        planning_agent: Optional[PlanningAgent] = None,
        generation_agent: Optional[GenerationAgent] = None,
        verification_agent: Optional[VerificationAgent] = None,
        planning_llm: Optional[BaseLLM] = None,
        generation_llm: Optional[BaseLLM] = None,
        verification_llm: Optional[BaseLLM] = None,
        lean_runner: Optional[Lean4Runner] = None,
        max_retries: int = 5
    ):
        # 1.åˆ›å»ºé»˜è®¤çš„llm
        if planning_llm is None:
            planning_config = LLMConfig(model_name="o3-mini", temperature=0.7)
            planning_llm = LLMFactory.create_llm(planning_config)
        if generation_llm is None:
            generation_config = LLMConfig(model_name="gpt-4o", temperature=0.7)
            generation_llm = LLMFactory.create_llm(generation_config)
        if verification_llm is None:
            verification_config = LLMConfig(
                model_name="o3-mini", temperature=0.7)
            verification_llm = LLMFactory.create_llm(verification_config)
        self.max_retries = max_retries

        # 2.åˆ›å»ºæ™ºèƒ½ä½“
        if planning_agent is None:
            self.planning_agent = PlanningAgent(planning_llm)
            logger.info(f"è§„åˆ’æ™ºèƒ½ä½“: {self.planning_agent}")
        if generation_agent is None:
            self.generation_agent = GenerationAgent(generation_llm)
            logger.info(f"ç”Ÿæˆæ™ºèƒ½ä½“: {self.generation_agent}")
        if verification_agent is None:
            self.verification_agent = VerificationAgent(
                lean_runner, verification_llm)
            logger.info(f"éªŒè¯æ™ºèƒ½ä½“: {self.verification_agent}")

    @classmethod
    def from_config(
        cls,
        config_manager: Optional[Union[ConfigManager, str]] = None,
        config: Optional[Dict] = None
    ) -> 'AgentCoordinator':
        """
        ä»é…ç½®åˆ›å»ºåè°ƒå™¨

        Args:
            config_manager: ConfigManager å®ä¾‹æˆ–é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰
            config: å¯é€‰çš„é…ç½®å­—å…¸ï¼Œç”¨äºè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®

        Returns:
            AgentCoordinator: åè°ƒå™¨å®ä¾‹
        """
        # 1. å¤„ç† config_manager å‚æ•°
        if config_manager is None:
            # é»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶
            config_file = "config/default.yaml"
            config_manager = ConfigManager(config_file)
        elif isinstance(config_manager, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå½“ä½œé…ç½®æ–‡ä»¶è·¯å¾„
            config_file = config_manager
            config_manager = ConfigManager(config_file)
        # å¦‚æœå·²ç»æ˜¯ ConfigManager å®ä¾‹ï¼Œç›´æ¥ä½¿ç”¨

        # 2. ä» ConfigManager åŠ è½½ LLM é…ç½®
        try:
            planning_config_dict = config_manager.get_llm_config("planning")
            generation_config_dict = config_manager.get_llm_config(
                "generation")
            verification_config_dict = config_manager.get_llm_config(
                "verification")

            # è½¬æ¢ä¸º LLMConfig å¯¹è±¡
            planning_config = ConfigLoader.load_from_dict(planning_config_dict)
            generation_config = ConfigLoader.load_from_dict(
                generation_config_dict)
            verification_config = ConfigLoader.load_from_dict(
                verification_config_dict)
        except Exception as e:
            logger.warning(f"æ— æ³•ä»é…ç½®æ–‡ä»¶åŠ è½½ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            planning_config = LLMConfig(
                model_name="gpt-4o-mini", temperature=0.7)
            generation_config = LLMConfig(model_name="gpt-4o", temperature=0.7)
            verification_config = LLMConfig(
                model_name="gpt-4o-mini", temperature=0.7)

        # 3. ä½¿ç”¨ config å­—å…¸è¦†ç›–é…ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
        if config is not None:
            if "planning_model" in config:
                planning_config.model_name = config["planning_model"]
            if "planning_temperature" in config:
                planning_config.temperature = config["planning_temperature"]
            if "generation_model" in config:
                generation_config.model_name = config["generation_model"]
            if "generation_temperature" in config:
                generation_config.temperature = config["generation_temperature"]
            if "verification_model" in config:
                verification_config.model_name = config["verification_model"]
            if "verification_temperature" in config:
                verification_config.temperature = config["verification_temperature"]

        # 4. åˆ›å»º LLM å®ä¾‹
        planning_llm = LLMFactory.create_llm(planning_config)
        generation_llm = LLMFactory.create_llm(generation_config)
        verification_llm = LLMFactory.create_llm(verification_config)
        lean_runner = Lean4Runner(
            project_path=config_manager.get_verifier_config().get("project_path"),)

        # 5. è·å– max_retries
        max_retries = config_manager.get_max_retries()

        return cls(
            planning_llm=planning_llm,
            generation_llm=generation_llm,
            verification_llm=verification_llm,
            lean_runner=lean_runner,
            max_retries=max_retries
        )

    def solve(self, problem_description: str, task_template: str) -> Dict[str, str]:
        """
        è§£å†³é—®é¢˜çš„ä¸»æµç¨‹
        """
        state = AgentState(
            problem_description=problem_description,
            task_template=task_template,
            max_retries=self.max_retries
        )

        # 1. è§„åˆ’é˜¶æ®µ
        planning_result = self.planning_agent.execute(state)
        logger.info(f"è§„åˆ’é˜¶æ®µç»“æœ: {planning_result}")

        last_error: Optional[str] = None

        for attempt in range(state.max_retries):
            state.retry_count = attempt
            logger.info(
                f"===== ç¬¬ {attempt + 1}/{state.max_retries} è½®ç”Ÿæˆ-éªŒè¯ =====")

            # 2. ç”Ÿæˆé˜¶æ®µ
            generation_result = self.generation_agent.execute(state)
            logger.info(f"ç”Ÿæˆé˜¶æ®µç»“æœ: {generation_result}")

            # 3. éªŒè¯é˜¶æ®µ
            verification_result = self.verification_agent.execute(state)
            logger.info(f"éªŒè¯é˜¶æ®µç»“æœ: {verification_result}")

            if verification_result.get("success"):
                logger.info("âœ… è¯æ˜éªŒè¯é€šè¿‡ï¼Œæµç¨‹ç»“æŸ")
                return {
                    "success": True,
                    "proof": state.current_proof,
                    "verification_output": verification_result.get("output"),
                    "attempts": attempt + 1
                }

            last_error = verification_result.get(
                "error") or "Unknown verification error"
            logger.warning(
                f"âŒ ç¬¬ {attempt + 1} è½®éªŒè¯å¤±è´¥: {last_error}. å°†é”™è¯¯åé¦ˆç»™ç”Ÿæˆé˜¶æ®µé‡è¯•ã€‚")

        logger.error("ğŸš« è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ä»æœªé€šè¿‡éªŒè¯")
        return {
            "success": False,
            "proof": state.current_proof,
            "error": last_error,
            "attempts": state.max_retries
        }
